{"version":"1","records":[{"hierarchy":{"lvl1":"Physical Oceanography Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook"},"type":"lvl1","url":"/#physical-oceanography-cookbook","position":2},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook"},"content":"\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/#physical-oceanography-cookbook","position":3},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Motivation"},"content":"(Add a few sentences stating why this cookbook will be useful. What skills will you, “the chef”, gain once you have reached the end of the cookbook?)","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":6},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Authors"},"content":"First Author, \n\nSecond Author, etc. Acknowledge primary content authors here","type":"content","url":"/#authors","position":7},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":8},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":9},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":10},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - “Foundations” and “Example Workflows.” Then, describe each section below.)","type":"content","url":"/#structure","position":11},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":12},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":13},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":14},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":15},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":16},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":17},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":18},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":19},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":20},{"hierarchy":{"lvl1":"Physical Oceanography Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace “cookbook-example” with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":21},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis"},"type":"lvl1","url":"/notebooks/sea-surface-height","position":0},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis"},"content":"For this example we will use \n\ngridded sea-surface altimetry data from The Copernicus Marine Environment. This is a widely used dataset in physical oceanography and climate.\n\nThe dataset has  been extracted from Copernicus and stored in google cloud storage in \n\nxarray-zarr format. It is catalogues in the Pangeo Cloud Catalog at \n\nhttps://​catalog​.pangeo​.io​/browse​/master​/ocean​/sea​_surface​_height/\n\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport hvplot.xarray\nplt.rcParams['figure.figsize'] = (15,10)\n%matplotlib inline\n\n","type":"content","url":"/notebooks/sea-surface-height","position":1},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl3":"Initialize Dataset"},"type":"lvl3","url":"/notebooks/sea-surface-height#initialize-dataset","position":2},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl3":"Initialize Dataset"},"content":"Here we load the dataset from the zarr store. Note that this very large dataset initializes nearly instantly, and we can see the full list of variables and coordinates, including metadata for each variable.\n\nfrom intake import open_catalog\ncat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\nds  = cat[\"sea_surface_height\"].to_dask()\nds\n\n","type":"content","url":"/notebooks/sea-surface-height#initialize-dataset","position":3},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Visually Examine Some of the Data"},"type":"lvl2","url":"/notebooks/sea-surface-height#visually-examine-some-of-the-data","position":4},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Visually Examine Some of the Data"},"content":"Let’s do a sanity check that the data looks reasonable. Here we use the \n\nhvplot interactive plotting library.\n\nds.sla.hvplot.image('longitude', 'latitude',\n                    rasterize=True, dynamic=True, width=800, height=450, \n                    widget_type='scrubber', widget_location='bottom', cmap='RdBu_r')\n\n","type":"content","url":"/notebooks/sea-surface-height#visually-examine-some-of-the-data","position":5},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl3":"Create and Connect to Dask Distributed Cluster","lvl2":"Visually Examine Some of the Data"},"type":"lvl3","url":"/notebooks/sea-surface-height#create-and-connect-to-dask-distributed-cluster","position":6},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl3":"Create and Connect to Dask Distributed Cluster","lvl2":"Visually Examine Some of the Data"},"content":"\n\nfrom dask_gateway import Gateway\nfrom dask.distributed import Client\n\ngateway = Gateway()\ncluster = gateway.new_cluster()\ncluster.adapt(minimum=1, maximum=20)\ncluster\n\n** ☝️ Don’t forget to click the link above to view the scheduler dashboard! **\n\nclient = Client(cluster)\nclient\n\n","type":"content","url":"/notebooks/sea-surface-height#create-and-connect-to-dask-distributed-cluster","position":7},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Timeseries of Global Mean Sea Level"},"type":"lvl2","url":"/notebooks/sea-surface-height#timeseries-of-global-mean-sea-level","position":8},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Timeseries of Global Mean Sea Level"},"content":"Here we make a simple yet fundamental calculation: the rate of increase of global mean sea level over the observational period.\n\n# the number of GB involved in the reduction\nds.sla.nbytes/1e9\n\n# the computationally intensive step\nsla_timeseries = ds.sla.mean(dim=('latitude', 'longitude')).load()\n\nsla_timeseries.plot(label='full data')\nsla_timeseries.rolling(time=365, center=True).mean().plot(label='rolling annual mean')\nplt.ylabel('Sea Level Anomaly [m]')\nplt.title('Global Mean Sea Level')\nplt.legend()\nplt.grid()\n\nIn order to understand how the sea level rise is distributed in latitude, we can make a sort of \n\nHovmöller diagram.\n\nsla_hov = ds.sla.mean(dim='longitude').load()\n\nfig, ax = plt.subplots(figsize=(12, 4))\nsla_hov.name = 'Sea Level Anomaly [m]'\nsla_hov.transpose().plot(vmax=0.2, ax=ax)\n\nWe can see that most sea level rise is actually in the Southern Hemisphere.\n\n","type":"content","url":"/notebooks/sea-surface-height#timeseries-of-global-mean-sea-level","position":9},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Sea Level Variability"},"type":"lvl2","url":"/notebooks/sea-surface-height#sea-level-variability","position":10},{"hierarchy":{"lvl1":"Sea Surface Altimetry Data Analysis","lvl2":"Sea Level Variability"},"content":"We can examine the natural variability in sea level by looking at its standard deviation in time.\n\nsla_std = ds.sla.std(dim='time').load()\nsla_std.name = 'Sea Level Variability [m]'\n\nax = sla_std.plot()\n_ = plt.title('Sea Level Variability')","type":"content","url":"/notebooks/sea-surface-height#sea-level-variability","position":11},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis"},"type":"lvl1","url":"/notebooks/along-track","position":0},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis"},"content":"\n\n\n","type":"content","url":"/notebooks/along-track","position":1},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis"},"type":"lvl1","url":"/notebooks/along-track#along-track-altimetry-analysis","position":2},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis"},"content":"\n\n\n\n","type":"content","url":"/notebooks/along-track#along-track-altimetry-analysis","position":3},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/along-track#overview","position":4},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Overview"},"content":"Using CNES altimetry data\n\nVisualizing data using hvplot\n\nUse xhistogram to plot multidimensional data\n\n","type":"content","url":"/notebooks/along-track#overview","position":5},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/along-track#prerequisites","position":6},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Pandas\n\nHelpful\n\n\n\nUsing hvplot\n\nHelpful\n\nMatplotlib knowledge also helpful\n\nDask\n\nHelpful\n\n\n\nxhistogram\n\nHelpful\n\n\n\nTime to learn: 15 minutes\n\n","type":"content","url":"/notebooks/along-track#prerequisites","position":7},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/along-track#imports","position":8},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Imports"},"content":"\n\n\n\nimport fsspec\nimport xarray as xr\nimport numpy as np\nimport hvplot\nimport hvplot.dask\nimport hvplot.pandas\nimport hvplot.xarray\nfrom xhistogram.xarray import histogram\nfrom intake import open_catalog\n\n","type":"content","url":"/notebooks/along-track#imports","position":9},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Load Data"},"type":"lvl2","url":"/notebooks/along-track#load-data","position":10},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Load Data"},"content":"The analysis ready along-track altimetry data were prepared by CNES. They are catalogged in the Pangeo Cloud Data Catalog here: \n\nhttps://​catalog​.pangeo​.io​/browse​/master​/ocean​/altimetry/\n\nWe will work with Jason 3.\n\ncat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean/altimetry.yaml\")\nprint(list(cat))\nds = cat['j3'].to_dask()\nds\n\nLoad some data into memory:\n\n# Select latitude, longitude, and sea level anomaly\nds_ll = ds[['latitude', 'longitude', 'sla_filtered']].reset_coords().astype('f4').load()\nds_ll\n\nConvert to pandas dataframe:\n\ndf = ds_ll.to_dataframe()\ndf\n\n","type":"content","url":"/notebooks/along-track#load-data","position":11},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Visualize with hvplot"},"type":"lvl2","url":"/notebooks/along-track#visualize-with-hvplot","position":12},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Visualize with hvplot"},"content":"\n\ndf.hvplot.scatter(x='longitude', y='latitude', datashade=True)\n\n","type":"content","url":"/notebooks/along-track#visualize-with-hvplot","position":13},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Bin using xhistogram"},"type":"lvl2","url":"/notebooks/along-track#bin-using-xhistogram","position":14},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Bin using xhistogram"},"content":"\n\nlon_bins = np.arange(0, 361, 2)\nlat_bins = np.arange(-70, 71, 2)\n\n# helps with memory management\nds_ll_chunked = ds_ll.chunk({'time': '5MB'})\n\nsla_variance = histogram(ds_ll_chunked.longitude, ds_ll_chunked.latitude,\n                         bins=[lon_bins, lat_bins],\n                         weights=ds_ll_chunked.sla_filtered.fillna(0.)**2)\n\nnorm = histogram(ds_ll_chunked.longitude, ds_ll_chunked.latitude,\n                         bins=[lon_bins, lat_bins])\n\n\n# let's get at least 200 points in a box for it to be unmasked\nthresh = 200\nsla_variance = sla_variance / norm.where(norm > thresh)\nsla_variance\n\nsla_variance.load()\n\n# plot the sea level anomaly variance\nsla_variance.plot(x='longitude_bin', figsize=(12, 6), vmax=0.2)\n\n","type":"content","url":"/notebooks/along-track#bin-using-xhistogram","position":15},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/along-track#summary","position":16},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Summary"},"content":"\n\n\n\nIn this example we visualized sea level anomalies using along-track altimetry data using hvplot. Then, we used xhistogram to calculate and plot the variance of the data.","type":"content","url":"/notebooks/along-track#summary","position":17},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/along-track#whats-next","position":18},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl3":"What’s next?","lvl2":"Summary"},"content":"Other examples will look at other datasets to visualize sea surface temeratures, ocean depth, and currents.\n\n","type":"content","url":"/notebooks/along-track#whats-next","position":19},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/along-track#resources-and-references","position":20},{"hierarchy":{"lvl1":"Along Track Altimetry Analysis","lvl2":"Resources and references"},"content":"This notebook is based on the Pangeo physical oceanography gallery example: \n\nhttps://​gallery​.pangeo​.io​/repos​/pangeo​-gallery​/physical​-oceanography​/02​_along​_track​.html","type":"content","url":"/notebooks/along-track#resources-and-references","position":21},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis"},"type":"lvl1","url":"/notebooks/cesm-mom6","position":0},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis"},"content":"This notebook shows how to load and analyze ocean data from an out-of-the-box MOM6/CESM G-case simulation (coupled ocean ocean/sea ice).\n\nNOTE: MOM6/CESM is not ready to be used for research.\n\n%matplotlib inline\n\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport holoviews as hv\nimport datashader\nfrom holoviews.operation.datashader import regrid, shade, datashade\n\nhv.extension('bokeh', width=100)\n\n","type":"content","url":"/notebooks/cesm-mom6","position":1},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Load MOM6/CESM Data"},"type":"lvl2","url":"/notebooks/cesm-mom6#load-mom6-cesm-data","position":2},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Load MOM6/CESM Data"},"content":"This data is stored in \n\nxarray-zarr format in Google Cloud Storage.\nThis format is optimized for parallel distributed reads from within the cloud environment.\n\nThe full data catalog is located here: \n\nhttps://​catalog​.pangeo​.io​/browse​/master​/ocean/\n\nimport intake\ncat = intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\nds = cat[\"cesm_mom6_example\"].to_dask()\nds\n\n","type":"content","url":"/notebooks/cesm-mom6#load-mom6-cesm-data","position":3},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Visualize SST Data with Holoviews and Datashader"},"type":"lvl2","url":"/notebooks/cesm-mom6#visualize-sst-data-with-holoviews-and-datashader","position":4},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Visualize SST Data with Holoviews and Datashader"},"content":"\n\nThe cells below show how to interactively explore the dataset.\n\nsst_ds = hv.Dataset(ds['SST'], kdims=['time', 'geolon', 'geolat'])\nsst = sst_ds.to(hv.QuadMesh, kdims=[\"geolon\", \"geolat\"], dynamic=True)\n%opts RGB [width=900 height=600] \ndatashade(sst, precompute=True, cmap=plt.cm.RdBu_r)\n\n","type":"content","url":"/notebooks/cesm-mom6#visualize-sst-data-with-holoviews-and-datashader","position":5},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Visualize SSS Data with Holoviews and Datashader"},"type":"lvl2","url":"/notebooks/cesm-mom6#visualize-sss-data-with-holoviews-and-datashader","position":6},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Visualize SSS Data with Holoviews and Datashader"},"content":"\n\nsss_ds = hv.Dataset(ds['SSS'], kdims=['time', 'geolon', 'geolat'])\nsss = sst_ds.to(hv.QuadMesh, kdims=[\"geolon\", \"geolat\"], dynamic=True)\n%opts RGB [width=900 height=600] \ndatashade(sss, precompute=True, cmap=plt.cm.Spectral_r)\n\n","type":"content","url":"/notebooks/cesm-mom6#visualize-sss-data-with-holoviews-and-datashader","position":7},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Create and Connect to Dask Distributed Cluster"},"type":"lvl2","url":"/notebooks/cesm-mom6#create-and-connect-to-dask-distributed-cluster","position":8},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Create and Connect to Dask Distributed Cluster"},"content":"This will launch a cluster of virtual machines in the cloud.\n\nfrom dask.distributed import Client\nfrom dask_gateway import GatewayCluster\ncluster = GatewayCluster()\ncluster.adapt(minimum=1, maximum=10)\ncluster\n\n👆 Don’t forget to click this link to get the cluster dashboard\n\nclient = Client(cluster)\nclient\n\n","type":"content","url":"/notebooks/cesm-mom6#create-and-connect-to-dask-distributed-cluster","position":9},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Data reduction"},"type":"lvl2","url":"/notebooks/cesm-mom6#data-reduction","position":10},{"hierarchy":{"lvl1":"MOM6/CESM Ocean Model Analysis","lvl2":"Data reduction"},"content":"Here we make a data reduction by taking the time of SST and SSS. This demonstrates how the cluster distributes the reads from storage.\n\nSST_mean = ds.SST.mean(dim=('time'))\nSST_mean\n\nSSS_mean = ds.SSS.mean(dim=('time'))\nSSS_mean\n\n%time SST_mean.load()\n\n# plot mean SST\nqm = hv.QuadMesh((ds.geolon.values, ds.geolat.values, SST_mean))\ndatashade(qm, precompute=True, cmap=plt.cm.RdBu_r)\n\n%time SSS_mean.load()\n\n# plot mean SSS\nqm = hv.QuadMesh((ds.geolon.values, ds.geolat.values, SSS_mean))\ndatashade(qm, precompute=True, cmap=plt.cm.Spectral_r)","type":"content","url":"/notebooks/cesm-mom6#data-reduction","position":11},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example"},"type":"lvl1","url":"/notebooks/eccov4","position":0},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example"},"content":"\n\n\n","type":"content","url":"/notebooks/eccov4","position":1},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example"},"type":"lvl1","url":"/notebooks/eccov4#mitgcm-eccov4-example","position":2},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example"},"content":"\n\n","type":"content","url":"/notebooks/eccov4#mitgcm-eccov4-example","position":3},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/eccov4#overview","position":4},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Overview"},"content":"This Jupyter notebook demonstrates how to use \n\nxarray and \n\nxgcm to analyze data from the \n\nECCO v4r3 ocean state estimate.\n\nLoading ECCO zarr data and converting to an xarray dataset\n\nVisualize ocean depth using cartopy\n\nIndexing and selecting data using xarray\n\nUse dask cluster to speed up reading the data\n\nCalculate and plot the horizontally integrated heat content anomaly\n\nUse xgcm to compute the time-mean convergence of veritcally-integrated heat fluxes\n\n","type":"content","url":"/notebooks/eccov4#overview","position":5},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/eccov4#prerequisites","position":6},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nHelpful\n\n\n\nXarray\n\nHelpful\n\nSlicing, indexing, basic statistics\n\nDask\n\nHelpful\n\n\n\nTime to learn: 1 hour\n\n","type":"content","url":"/notebooks/eccov4#prerequisites","position":7},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/eccov4#imports","position":8},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport intake\nimport cartopy as cart\nimport pyresample\nfrom dask_gateway import GatewayCluster\nfrom dask.distributed import Client\nimport xgcm\n\n","type":"content","url":"/notebooks/eccov4#imports","position":9},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Load the data"},"type":"lvl2","url":"/notebooks/eccov4#load-the-data","position":10},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Load the data"},"content":"The ECCOv4r3 data was converted from its raw MDS (.data / .meta file) format to zarr format, using the \n\nxmitgcm package. \n\nZarr is a powerful data storage format that can be thought of as an alternative to HDF. In contrast to HDF, zarr works very well with cloud object storage. Zarr is currently useable in python, java, C++, and julia. It is likely that zarr will form the basis of the next major version of the netCDF library.\n\nIf you’re curious, here are some resources to learn more about zarr:\n\nhttps://​zarr​.readthedocs​.io​/en​/stable​/tutorial​.html\n\nhttps://​speakerdeck​.com​/rabernat​/pangeo​-zarr​-cloud​-data​-storage\n\nhttps://​mrocklin​.github​.com​/blog​/work​/2018​/02​/06​/hdf​-in​-the​-cloud\n\nThe ECCO zarr data currently lives in \n\nGoogle Cloud Storage as part of the \n\nPangeo Data Catalog. This means we can open the whole dataset using one line of code.\n\nThis takes a bit of time to run because the metadata must be downloaded and parsed. The type of object returned is an \n\nXarray dataset.\n\ncat = intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\nds = cat.ECCOv4r3.to_dask()\nds\n\nNote that no data has been actually download yet. Xarray uses the approach of lazy evaluation, in which loading of data and execution of computations is delayed as long as possible (i.e. until data is actually needed for a plot). The data are represented symbolically as \n\ndask arrays. For example:SALT       (time, k, face, j, i) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\n\nThe full shape of the array is (288, 50, 13, 90, 90), quite large. But the chunksize is (1, 50, 13, 90, 90). Here the chunks correspond to the individual granuales of data (objects) in cloud storage. The chunk is the minimum amount of data we can read at one time.\n\n# a trick to make things work a bit faster\ncoords = ds.coords.to_dataset().reset_coords()\nds = ds.reset_coords(drop=True)\n\n","type":"content","url":"/notebooks/eccov4#load-the-data","position":11},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Visualizing Data"},"type":"lvl2","url":"/notebooks/eccov4#visualizing-data","position":12},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Visualizing Data"},"content":"","type":"content","url":"/notebooks/eccov4#visualizing-data","position":13},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"A Direct Plot","lvl2":"Visualizing Data"},"type":"lvl3","url":"/notebooks/eccov4#a-direct-plot","position":14},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"A Direct Plot","lvl2":"Visualizing Data"},"content":"Let’s try to visualize something simple: the Depth variable. Here is how the data are stored:Depth      (face, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(13, 90, 90)>\n\nAlthough depth is a 2D field, there is an extra, dimension (face) corresponding to the LLC face number. Let’s use xarray’s built in plotting functions to plot each face individually.\n\ncoords.Depth.plot(col='face', col_wrap=5)\n\nThis view is not the most useful. It reflects how the data is arranged logically, rather than geographically.","type":"content","url":"/notebooks/eccov4#a-direct-plot","position":15},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"A Pretty Map","lvl2":"Visualizing Data"},"type":"lvl3","url":"/notebooks/eccov4#a-pretty-map","position":16},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"A Pretty Map","lvl2":"Visualizing Data"},"content":"To make plotting easier, we can define a quick function to plot the data in a more geographically friendly way. Eventually these plotting functions may be provided by the gcmplots package: \n\nhttps://​github​.com​/xecco​/gcmplots. For now, it is easy enough to roll our own.\n\nclass LLCMapper:\n\n    def __init__(self, ds, dx=0.25, dy=0.25):\n        # Extract LLC 2D coordinates\n        lons_1d = ds.XC.values.ravel()\n        lats_1d = ds.YC.values.ravel()\n\n        # Define original grid\n        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n\n        # Longitudes latitudes to which we will we interpolate\n        lon_tmp = np.arange(-180, 180, dx) + dx/2\n        lat_tmp = np.arange(-90, 90, dy) + dy/2\n\n        # Define the lat lon points of the two parts.\n        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n                                                            lats=self.new_grid_lat)\n\n    def __call__(self, da, ax=None, projection=cart.crs.Robinson(), lon_0=-60, **plt_kwargs):\n\n        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': projection})\n        else:\n            m = plt.axes(projection=projection)\n            \n        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n                                                    self.new_grid,\n                                                    radius_of_influence=100000,\n                                                    fill_value=None)\n\n        vmax = plt_kwargs.pop('vmax', field.max())\n        vmin = plt_kwargs.pop('vmin', field.min())\n\n        \n        x,y = self.new_grid_lon, self.new_grid_lat\n\n        # Find index where data is splitted for mapping\n        split_lon_idx = round(x.shape[1]/(360/(lon_0 if lon_0>0 else lon_0+360)))\n\n\n        p = ax.pcolormesh(x[:,:split_lon_idx], y[:,:split_lon_idx], field[:,:split_lon_idx],\n                         vmax=vmax, vmin=vmin, transform=cart.crs.PlateCarree(), zorder=1, **plt_kwargs)\n        p = ax.pcolormesh(x[:,split_lon_idx:], y[:,split_lon_idx:], field[:,split_lon_idx:],\n                         vmax=vmax, vmin=vmin, transform=cart.crs.PlateCarree(), zorder=2, **plt_kwargs)\n\n        ax.add_feature(cart.feature.LAND, facecolor='0.5', zorder=3)\n        label = ''\n        if da.name is not None:\n            label = da.name\n        if 'units' in da.attrs:\n            label += ' [%s]' % da.attrs['units']\n        cb = plt.colorbar(p, shrink=0.4, label=label)\n        return ax\n\n\nmapper = LLCMapper(coords)\nmapper(coords.Depth);\n\nWe can use this with any 2D cell-centered LLC variable.","type":"content","url":"/notebooks/eccov4#a-pretty-map","position":17},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Selecting data"},"type":"lvl2","url":"/notebooks/eccov4#selecting-data","position":18},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Selecting data"},"content":"The entire ECCOv4e3 dataset is contained in a single Xarray.Dataset object. How do we find a view specific pieces of data? This is handled by Xarray’s \n\nindexing and selecting functions. To get the SST from January 2000, we do this:\n\nsst = ds.THETA.sel(time='2000-01-15', k=0)\nsst\n\nStill no data has been actually downloaded. That doesn’t happen until we call .load() explicitly or try to make a plot.\n\nmapper(sst, cmap='RdBu_r');\n\n","type":"content","url":"/notebooks/eccov4#selecting-data","position":19},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Do some Calculations"},"type":"lvl2","url":"/notebooks/eccov4#do-some-calculations","position":20},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Do some Calculations"},"content":"Now let’s start doing something besides just plotting the existing data. For example, let’s calculate the time-mean SST.\n\nmean_sst = ds.THETA.sel(k=0).mean(dim='time')\nmean_sst\n\nAs usual, no data was loaded. Instead, mean_sst is a symbolic representation of the data that needs to be pulled and the computations that need to be executed to produce the desired result. In this case, the 288 original chunks all need to be read from cloud storage. Dask coordinates this automatically for us. But it does take some time.\n\n%time mean_sst.load()\n\nmapper(mean_sst, cmap='RdBu_r');\n\n","type":"content","url":"/notebooks/eccov4#do-some-calculations","position":21},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Speeding things up with a Dask Cluster"},"type":"lvl2","url":"/notebooks/eccov4#speeding-things-up-with-a-dask-cluster","position":22},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Speeding things up with a Dask Cluster"},"content":"How can we speed things up? In general, the main bottleneck for this type of data analysis is the speed with which we can read the data. With cloud storage, the access is highly parallelizeable.\n\nFrom a Pangeo environment, we can create a \n\nDask cluster to spread the work out amongst many compute nodes. This works on both HPC and cloud. In the cloud, the compute nodes are provisioned on the fly and can be shut down as soon as we are done with our analysis.\n\nThe code below will create a cluster with five compute nodes. It can take a few minutes to provision our nodes.\n\ncluster = GatewayCluster()\ncluster.scale(5)\nclient = Client(cluster)\ncluster\n\nNow we re-run the mean calculation. Note how the dashboard helps us visualize what the cluster is doing.\n\n%time ds.THETA.isel(k=0).mean(dim='time').load()\n\n","type":"content","url":"/notebooks/eccov4#speeding-things-up-with-a-dask-cluster","position":23},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Spatially-Integrated Heat Content Anomaly"},"type":"lvl2","url":"/notebooks/eccov4#spatially-integrated-heat-content-anomaly","position":24},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Spatially-Integrated Heat Content Anomaly"},"content":"Now let’s do something harder. We will calculate the horizontally integrated heat content anomaly for the full 3D model domain.\n\n# the monthly climatology\ntheta_clim = ds.THETA.groupby('time.month').mean(dim='time')\n# the anomaly\ntheta_anom = ds.THETA.groupby('time.month') - theta_clim\nrho0 = 1029\ncp = 3994\nohc = rho0 * cp * (theta_anom *\n                   coords.rA *\n                   coords.hFacC).sum(dim=['face', 'j', 'i'])\nohc\n\n# actually load the data\nohc.load()\n# put the depth coordinate back for plotting purposes\nohc.coords['Z'] = coords.Z\nohc.swap_dims({'k': 'Z'}).transpose().plot(vmax=1e20)\n\n","type":"content","url":"/notebooks/eccov4#spatially-integrated-heat-content-anomaly","position":25},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Spatial Derivatives: Heat Budget"},"type":"lvl2","url":"/notebooks/eccov4#spatial-derivatives-heat-budget","position":26},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Spatial Derivatives: Heat Budget"},"content":"As our final exercise, we will do something much more complicated. We will compute the time-mean convergence of vertically-integrated heat fluxes. This is hard for several reasons.\n\nThe first reason it is hard is because it involves variables located at different grid points.\nFollowing MITgcm conventions, xmitgcm (which produced this dataset) labels the center point with the coordinates j, i, the u-velocity point as j, i_g, and the v-velocity point as j_g, i.\nThe horizontal advective heat flux variables areADVx_TH    (time, k, face, j, i_g) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\nADVy_TH    (time, k, face, j_g, i) float32 dask.array<shape=(288, 50, 13, 90, 90), chunksize=(1, 50, 13, 90, 90)>\n\nXarray won’t allow us to add or multiply variables that have different dimensions, and xarray by itself doesn’t understand how to transform from one grid position to another.\n\nThat’s why \n\nxgcm was created.\n\nXgcm allows us to create a Grid object, which understands how to interpolate and take differences in a way that is compatible with finite volume models such at MITgcm. Xgcm also works with many other models, including ROMS, POP, MOM5/6, NEMO, etc.\n\nA second reason this is hard is because of the complex topology connecting the different MITgcm faces. Fortunately xgcm also \n\nsupports this.\n\n# define the connectivity between faces\nface_connections = {'face':\n                    {0: {'X':  ((12, 'Y', False), (3, 'X', False)),\n                         'Y':  (None,             (1, 'Y', False))},\n                     1: {'X':  ((11, 'Y', False), (4, 'X', False)),\n                         'Y':  ((0, 'Y', False),  (2, 'Y', False))},\n                     2: {'X':  ((10, 'Y', False), (5, 'X', False)),\n                         'Y':  ((1, 'Y', False),  (6, 'X', False))},\n                     3: {'X':  ((0, 'X', False),  (9, 'Y', False)),\n                         'Y':  (None,             (4, 'Y', False))},\n                     4: {'X':  ((1, 'X', False),  (8, 'Y', False)),\n                         'Y':  ((3, 'Y', False),  (5, 'Y', False))},\n                     5: {'X':  ((2, 'X', False),  (7, 'Y', False)),\n                         'Y':  ((4, 'Y', False),  (6, 'Y', False))},\n                     6: {'X':  ((2, 'Y', False),  (7, 'X', False)),\n                         'Y':  ((5, 'Y', False),  (10, 'X', False))},\n                     7: {'X':  ((6, 'X', False),  (8, 'X', False)),\n                         'Y':  ((5, 'X', False),  (10, 'Y', False))},\n                     8: {'X':  ((7, 'X', False),  (9, 'X', False)),\n                         'Y':  ((4, 'X', False),  (11, 'Y', False))},\n                     9: {'X':  ((8, 'X', False),  None),\n                         'Y':  ((3, 'X', False),  (12, 'Y', False))},\n                     10: {'X': ((6, 'Y', False),  (11, 'X', False)),\n                          'Y': ((7, 'Y', False),  (2, 'X', False))},\n                     11: {'X': ((10, 'X', False), (12, 'X', False)),\n                          'Y': ((8, 'Y', False),  (1, 'X', False))},\n                     12: {'X': ((11, 'X', False), None),\n                          'Y': ((9, 'Y', False),  (0, 'X', False))}}}\n\n# create the grid object\ngrid = xgcm.Grid(ds, periodic=False, face_connections=face_connections)\ngrid\n\nNow we can use the grid object we created to take the divergence of a 2D vector\n\n# vertical integral and time mean of horizontal diffusive heat flux\nadvx_th_vint = ds.ADVx_TH.sum(dim='k').mean(dim='time')\nadvy_th_vint = ds.ADVy_TH.sum(dim='k').mean(dim='time')\n\n# difference in the x and y directions\ndiff_ADV_th = grid.diff_2d_vector({'X': advx_th_vint, 'Y': advy_th_vint}, boundary='fill')\n# convergence\nconv_ADV_th = -diff_ADV_th['X'] - diff_ADV_th['Y']\nconv_ADV_th\n\n# vertical integral and time mean of horizontal diffusive heat flux\ndifx_th_vint = ds.DFxE_TH.sum(dim='k').mean(dim='time')\ndify_th_vint = ds.DFyE_TH.sum(dim='k').mean(dim='time')\n\n# difference in the x and y directions\ndiff_DIF_th = grid.diff_2d_vector({'X': difx_th_vint, 'Y': dify_th_vint}, boundary='fill')\n# convergence\nconv_DIF_th = -diff_DIF_th['X'] - diff_DIF_th['Y']\nconv_DIF_th\n\n# convert to Watts / m^2 and load\nmean_adv_conv = rho0 * cp * (conv_ADV_th/coords.rA).fillna(0.).load()\nmean_dif_conv = rho0 * cp * (conv_DIF_th/coords.rA).fillna(0.).load()\n\nax = mapper(mean_adv_conv, cmap='RdBu_r', vmax=300, vmin=-300);\nax.set_title(r'Convergence of Advective Flux (W/m$^2$)');\n\nax = mapper(mean_dif_conv, cmap='RdBu_r', vmax=300, vmin=-300)\nax.set_title(r'Convergence of Diffusive Flux (W/m$^2$)');\n\nax = mapper(mean_dif_conv + mean_adv_conv, cmap='RdBu_r', vmax=300, vmin=-300)\nax.set_title(r'Convergence of Net Horizontal Flux (W/m$^2$)');\n\nax = mapper(ds.TFLUX.mean(dim='time').load(), cmap='RdBu_r', vmax=300, vmin=-300);\nax.set_title(r'Surface Heat Flux (W/m$^2$)');\n\n\n\n","type":"content","url":"/notebooks/eccov4#spatial-derivatives-heat-budget","position":27},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/eccov4#summary","position":28},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Summary"},"content":"In this example we used xarray and cartopy to visualize ocean depth and ocean heat content anomalies. Then, we used xgcm to easily work with variables that have different dimensions.","type":"content","url":"/notebooks/eccov4#summary","position":29},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/eccov4#whats-next","position":30},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl3":"What’s next?","lvl2":"Summary"},"content":"In our last example, we will visualize ocean currents.\n\n","type":"content","url":"/notebooks/eccov4#whats-next","position":31},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/eccov4#resources-and-references","position":32},{"hierarchy":{"lvl1":"MITgcm ECCOv4 Example","lvl2":"Resources and references"},"content":"This notebook is based on the ECCOv4 example from the Pangeo physical oceanography gallery: \n\nhttp://​gallery​.pangeo​.io​/repos​/pangeo​-gallery​/physical​-oceanography​/04​_eccov4​.html","type":"content","url":"/notebooks/eccov4#resources-and-references","position":33},{"hierarchy":{"lvl1":"Gulf Stream Currents"},"type":"lvl1","url":"/notebooks/gulf-stream-currents","position":0},{"hierarchy":{"lvl1":"Gulf Stream Currents"},"content":"\n\n\n","type":"content","url":"/notebooks/gulf-stream-currents","position":1},{"hierarchy":{"lvl1":"Gulf Stream Currents"},"type":"lvl1","url":"/notebooks/gulf-stream-currents#gulf-stream-currents","position":2},{"hierarchy":{"lvl1":"Gulf Stream Currents"},"content":"\n\n\n\n","type":"content","url":"/notebooks/gulf-stream-currents#gulf-stream-currents","position":3},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#overview","position":4},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Overview"},"content":"An example that uses ipyleaflet to reproduce style of visualization used in the New York Times article\n\n\nIn the Atlantic Ocean, Subtle Shifts Hint at Dramatic Dangers (March 2, 20121).\n\nOpen an Intake catalogue reference Sea Surface Height data\n\nMake a geographic map of the data using ipyleaflet\n\n","type":"content","url":"/notebooks/gulf-stream-currents#overview","position":5},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#prerequisites","position":6},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nXarray\n\nHelpful\n\n\n\nDask\n\nHelpful\n\n\n\nIntake\n\nHelpful\n\n\n\nipyleaflet\n\nHelpful\n\n\n\nTime to learn: 15 minutes\n\n","type":"content","url":"/notebooks/gulf-stream-currents#prerequisites","position":7},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#imports","position":8},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Imports"},"content":"\n\n\n\nfrom ipyleaflet import Map, TileLayer, basemaps\nfrom ipyleaflet.velocity import Velocity\nfrom intake import open_catalog\n\n","type":"content","url":"/notebooks/gulf-stream-currents#imports","position":9},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Load Data"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#load-data","position":10},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Load Data"},"content":"The \n\nCopernicus Monitoring Environment Marine Service (CMEMS) is a large repository of ocean products including in-situ observations, satellite based remote sensing data, and numerical model output.\n\nWe want to look at altimeter satellite data to show the Sea Level Anomalies (SLA) for the global ocean. The particular data product is called Global Ocean Gridded L4 Sea Surface Heights and Derived Variables Reprocessed (1993-Ongoing) (\n\nSEALEVEL​_GLO​_PHY​_L4​_MY​_008​_047).\n\nThis dataset is available as an analysis-ready on the Pangeo Cloud Data Catalog\n\ncat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\ncat[\"sea_surface_height\"]\n\nThis dataset is marked “requester pays” which means we have do an addtional step if we are not already on Pangeo Hub on the Google Cloud Platform.\n\n","type":"content","url":"/notebooks/gulf-stream-currents#load-data","position":11},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl3":"Working with requester pays data","lvl2":"Load Data"},"type":"lvl3","url":"/notebooks/gulf-stream-currents#working-with-requester-pays-data","position":12},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl3":"Working with requester pays data","lvl2":"Load Data"},"content":"Several of the datasets within the Pangeo cloud data catalog are contained in \n\nrequester pays storage buckets. This means that a user requesting data must provide their own billing project (created and authenticated through Google Cloud Platform) to be billed for the charges associated with accessing a dataset. To set up an GCP billing project and use it for authentication in applications:\n\nCreate a project on GCP; if this is the first time using GCP, a prompt will appear to choose a Google account to link to all GCP-related activities.\n\nCreate a Cloud Billing account associated with the project and \n\nenable billing for the project through this account.\n\nUsing \n\nGoogle Cloud IAM, add the Service Usage Consumer role to your account, which enables it to make billed requests on the behalf of the project.\nThrough command line, install the \n\nGoogle Cloud SDK; this can be done using conda:\n\nconda install -c conda-forge google-cloud-sdk\n\nInitialize the gcloud command line interface, logging into the account used to create the aforementioned project and selecting it as the default project; this will allow the project to be used for requester pays access through the command line:\n\ngcloud init```\n\nFinally, use gcloud to establish application default credentials; this will allow the project to be used for requester pays access through applications:\n\ngcloud auth application-default login\n\nds  = cat[\"sea_surface_height\"].to_dask()\nds\n\n","type":"content","url":"/notebooks/gulf-stream-currents#working-with-requester-pays-data","position":13},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Make a Map"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#make-a-map","position":14},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Make a Map"},"content":"\n\ncenter = [35, -50]\nzoom = 4\nm = Map(center=center, zoom=zoom, interpolation='nearest', basemap=basemaps.Gaode.Satellite)\n\ndisplay_options = {\n    'velocityType': 'Global Wind',\n    'displayPosition': 'bottomleft',\n    'displayEmptyString': 'No wind data'\n}\n\nwind = Velocity(\n    data=ds.isel(time=-1), \n    zonal_speed='ugos', meridional_speed='vgos', \n    latitude_dimension='latitude', longitude_dimension='longitude', \n    velocity_scale=0.2, max_velocity=1, \n    display_options=display_options\n)\n\nm.add_layer(wind)\n\nm\n\n\n\n","type":"content","url":"/notebooks/gulf-stream-currents#make-a-map","position":15},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#summary","position":16},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Summary"},"content":"\n\nIn this example we loaded sea level data from an analysis-ready cloud based dataset and made a visualization of that data using mapping library.\n\n","type":"content","url":"/notebooks/gulf-stream-currents#summary","position":17},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/gulf-stream-currents#resources-and-references","position":18},{"hierarchy":{"lvl1":"Gulf Stream Currents","lvl2":"Resources and references"},"content":"This notebook is based on the Pangeo physical oceanography gallery example: \n\nhttps://​gallery​.pangeo​.io​/repos​/pangeo​-gallery​/physical​-oceanography​/05​_gulf​_stream​_currents​.html","type":"content","url":"/notebooks/gulf-stream-currents#resources-and-references","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/notebook-template","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with Markdown syntax,\n\n![<image title>](http://link.com/to/image.png \"image alt text\")\n\nor edit this cell to see raw HTML img demonstration. This is preferred if you need to shrink your embedded image. Either way be sure to include alt text for any embedded images to make your content more accessible.\n\n\n\n","type":"content","url":"/notebooks/notebook-template","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/notebook-template#project-pythia-notebook-template","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Next, title your notebook appropriately with a top-level Markdown header, #. Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive. Follow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/notebook-template#project-pythia-notebook-template","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/notebook-template#overview","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/notebook-template#overview","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/notebook-template#prerequisites","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/notebook-template#prerequisites","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/notebook-template#imports","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/notebook-template#imports","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-first-content-section","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/notebook-template#your-first-content-section","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\nnew = \"helpful information\"\n\n","type":"content","url":"/notebooks/notebook-template#a-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#another-content-subsection","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/notebook-template#another-content-subsection","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-second-content-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate\n\n","type":"content","url":"/notebooks/notebook-template#your-second-content-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/notebook-template#subsection-to-the-second-section","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#subsection-to-the-second-section","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/notebook-template#a-quick-demonstration","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-quick-demonstration","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/notebook-template#of-further-and-further","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#of-further-and-further","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/notebook-template#header-levels","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"Subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax (demo below from link),\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nJupyter docs for Jupyter-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/notebook-template#header-levels","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/notebook-template#last-section","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"If you’re comfortable, and as we briefly used for our embedded logo up top, you can embed raw html into Jupyter Markdown cells (edit to see):\n\nInfoYour relevant information here!\n\nFeel free to copy this around and edit or play around with yourself. Some other admonitions you can put in:\n\nSuccessWe got this done after all!\n\nWarningBe careful!\n\nDangerScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/notebook-template#last-section","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/notebook-template#summary","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/notebook-template#summary","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/notebook-template#whats-next","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/notebook-template#whats-next","position":31},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/notebook-template#resources-and-references","position":32},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/notebook-template#resources-and-references","position":33}]}